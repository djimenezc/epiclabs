package com.djimenezc.duplicatedUrls;

/**
 * You have a file with 10 billion of urls (one per line).
 * These are the full list of urls to be crawled by your crawler.
 * How do you determine what urlâ€™s are duplicated?
 * Assume you have just 1 GB of memory available for this
 * <p>
 * Created by david on 19/06/2016.
 */
class UrlCrawler {
}
